{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04244a9f-77be-4f54-9d6e-6996ad0f4ce5",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing with Pandas\n",
    "\n",
    "## Task List\n",
    "\n",
    "1. **Identify missing values** ü§î\n",
    "2. **Drop rows with missing values** üí∏\n",
    "3. **Drop columns with missing values** üóëÔ∏è\n",
    "4. **Fill missing values** üìù\n",
    "5. **Forward/Backward fill** üîÑ\n",
    "6. **Interpolate missing values** üìà\n",
    "7. **Convert data type** üîÑ\n",
    "8. **Transform values** üéâ\n",
    "9. **Normalize (Min-Max)** üìä\n",
    "10. **Standardize (z-score)** üìà\n",
    "11. **Identify duplicates** üîç\n",
    "12. **Drop duplicates** üí∏\n",
    "13. **Drop duplicates (specific columns)** üóëÔ∏è\n",
    "14. **Lowercase strings** üìù\n",
    "15. **Remove spaces** üíª\n",
    "16. **Replace substring** üîÑ\n",
    "17. **Extract substring** üìä\n",
    "18. **Convert to datetime** üï∞Ô∏è\n",
    "19. **Extract year/month/day** üìÜ\n",
    "20. **Filter by date range** üìÖ\n",
    "21. **One-hot encoding** üìä\n",
    "22. **Label encoding** üìà\n",
    "23. **Group categories** üóëÔ∏è\n",
    "24. **Merge DataFrames** ü§ù\n",
    "25. **Concatenate (vertical)** üìã\n",
    "26. **Concatenate (horizontal)** üìä\n",
    "27. **Create new column** üìù\n",
    "28. **Discretize (bin)** üìä\n",
    "29. **Polynomial features** üìà\n",
    "\n",
    "## Let's get started! üíª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "aae4b885-36ff-4a00-8b2b-87bfd71a122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d97f33-7d10-4ed3-951d-9ab92ab132a8",
   "metadata": {},
   "source": [
    "1. Identify missing values in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c2f53330-b88f-4a75-9bfd-fc6930cf3e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "   A    B    C    D\n",
      "0  1  9.0  1.0  1.0\n",
      "1  2  2.0  NaN  2.0\n",
      "2  9  3.0  NaN  3.0\n",
      "3  4  NaN  4.0  4.0\n",
      "4  5  5.0  5.0  NaN\n",
      "Missing values in each column:\n",
      "A    0\n",
      "B    1\n",
      "C    2\n",
      "D    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#data set generated by GEN AI\n",
    "data = {\n",
    "    'A': [1, 2, 9, 4, 5],\n",
    "    'B': [9, 2, 3, np.nan, 5],\n",
    "    'C': [1, np.nan, np.nan, 4, 5],\n",
    "    'D': [1, 2, 3, 4, np.nan]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Data Frame:\\n{df}\")\n",
    "print(f\"Missing values in each column:\\n{df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c8271a-62eb-4405-8ec7-e2d7e9b17695",
   "metadata": {},
   "source": [
    "2. Drop rows with any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7cd353d4-b9f9-48ae-9446-d07e2c69237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "   A    B    C  D\n",
      "0  1  NaN  1.0  1\n",
      "1  2  2.0  NaN  2\n",
      "2  4  3.0  NaN  3\n",
      "3  4  NaN  4.0  4\n",
      "4  5  5.0  5.0  3\n",
      "Missing values in each column:\n",
      "   A    B    C  D\n",
      "4  5  5.0  5.0  3\n"
     ]
    }
   ],
   "source": [
    "#data set generated by GEN AI\n",
    "data = {\n",
    "    'A': [1, 2, 4, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, np.nan, np.nan, 4, 5],\n",
    "    'D': [1, 2, 3, 4, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Data Frame:\\n{df}\")\n",
    "print(f\"Missing values in each row:\\n{df.dropna(axis = 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf858b97-4317-4ec7-b9c5-b289d547743a",
   "metadata": {},
   "source": [
    "3. Drop columns with any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "305b5b98-70d9-44d2-a2c4-6b6769010c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "   A    B    C  D\n",
      "0  1  NaN  1.0  1\n",
      "1  2  2.0  NaN  2\n",
      "2  4  3.0  NaN  3\n",
      "3  4  NaN  4.0  4\n",
      "4  5  5.0  5.0  3\n",
      "Missing values in each column:\n",
      "   A  D\n",
      "0  1  1\n",
      "1  2  2\n",
      "2  4  3\n",
      "3  4  4\n",
      "4  5  3\n"
     ]
    }
   ],
   "source": [
    "#data set generated by GEN AI\n",
    "data = {\n",
    "    'A': [1, 2, 4, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, np.nan, np.nan, 4, 5],\n",
    "    'D': [1, 2, 3, 4, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Data Frame:\\n{df}\")\n",
    "print(f\"Missing values in each column:\\n{df.dropna(axis = 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054c979-49ab-40a9-8fff-733003b6d3c6",
   "metadata": {},
   "source": [
    "4. Fill missing values with a specific value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8d49454e-fda8-426b-8388-de0524fce24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "   A    B    C  D\n",
      "0  1  NaN  1.0  1\n",
      "1  2  2.0  NaN  2\n",
      "2  4  3.0  NaN  3\n",
      "3  4  NaN  4.0  4\n",
      "4  5  5.0  5.0  3\n",
      "Filled the missing values:\n",
      "   A    B    C  D\n",
      "0  1  4.0  1.0  1\n",
      "1  2  2.0  4.0  2\n",
      "2  4  3.0  4.0  3\n",
      "3  4  4.0  4.0  4\n",
      "4  5  5.0  5.0  3\n"
     ]
    }
   ],
   "source": [
    "#data set generated by GEN AI\n",
    "data = {\n",
    "    'A': [1, 2, 4, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, np.nan, np.nan, 4, 5],\n",
    "    'D': [1, 2, 3, 4, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Data Frame:\\n{df}\")\n",
    "print(f\"Filled the missing values:\\n{df.fillna(4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33650ed1-077b-45d0-a548-3061322dcb56",
   "metadata": {},
   "source": [
    "5. Fill missing values using forward fill and backward fill methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e31ae643-712a-46cd-94da-f8d592b52d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "   A    B    C  D\n",
      "0  1  NaN  1.0  1\n",
      "1  2  2.0  NaN  2\n",
      "2  4  3.0  NaN  3\n",
      "3  4  NaN  4.0  4\n",
      "4  5  5.0  5.0  3\n",
      "Forward Fill:\n",
      "   A    B    C  D\n",
      "0  1  NaN  1.0  1\n",
      "1  2  2.0  1.0  2\n",
      "2  4  3.0  1.0  3\n",
      "3  4  3.0  4.0  4\n",
      "4  5  5.0  5.0  3\n",
      "Backward Fill:\n",
      "   A    B    C  D\n",
      "0  1  2.0  1.0  1\n",
      "1  2  2.0  4.0  2\n",
      "2  4  3.0  4.0  3\n",
      "3  4  5.0  4.0  4\n",
      "4  5  5.0  5.0  3\n"
     ]
    }
   ],
   "source": [
    "#data set generated by GEN AI\n",
    "data = {\n",
    "    'A': [1, 2, 4, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, np.nan, np.nan, 4, 5],\n",
    "    'D': [1, 2, 3, 4, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Data Frame:\\n{df}\")\n",
    "print(f\"Forward Fill:\\n{df.ffill()}\") #propagate forward to fill the missing values\n",
    "print(f\"Backward Fill:\\n{df.bfill()}\") # propagate backword to fill the missin values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0d708e-ea52-4b94-85d4-a0f3de926177",
   "metadata": {},
   "source": [
    "6. Interpolate missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e03ad89-dbe2-456f-8cf8-14218773d96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "   A    B    C  D\n",
      "0  1  NaN  1.0  1\n",
      "1  2  2.0  NaN  2\n",
      "2  4  3.0  NaN  3\n",
      "3  4  NaN  4.0  4\n",
      "4  5  5.0  5.0  3\n",
      "Interpolated the missing values:\n",
      "   A    B    C  D\n",
      "0  1  NaN  1.0  1\n",
      "1  2  2.0  2.0  2\n",
      "2  4  3.0  3.0  3\n",
      "3  4  4.0  4.0  4\n",
      "4  5  5.0  5.0  3\n"
     ]
    }
   ],
   "source": [
    "#data set generated by GEN AI\n",
    "data = {\n",
    "    'A': [1, 2, 4, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, np.nan, np.nan, 4, 5],\n",
    "    'D': [1, 2, 3, 4, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Data Frame:\\n{df}\")\n",
    "print(f\"Interpolated the missing values:\\n{df.interpolate()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5874d3b7-4ea4-47ae-816f-aa2a77ca74a8",
   "metadata": {},
   "source": [
    "7. Convert a column to a different data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1d3fea0a-fe71-4232-8a5b-f31dc85fb534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "A      int64\n",
      "B    float64\n",
      "C    float64\n",
      "D      int64\n",
      "dtype: object\n",
      "\n",
      "Column A datatype changed from int to float:\n",
      "A    float64\n",
      "B    float64\n",
      "C    float64\n",
      "D      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#data set generated by GEN AI\n",
    "data = {\n",
    "    'A': [1, 2, 4, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, np.nan, np.nan, 4, 5],\n",
    "    'D': [1, 2, 3, 4, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Data Frame:\\n{df.dtypes}\\n\")\n",
    "print(f\"Column A datatype changed from int to float:\\n{df.astype({'A':'float'}).dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5929552-6e2f-451e-816e-43acb86f65ac",
   "metadata": {},
   "source": [
    "8. Apply a function to transform the values of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4c8b6ca8-8ed9-4ed2-96a5-fe5fb05f651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Frame:\n",
      "   A    B    C  D\n",
      "0  1  NaN  1.0  1\n",
      "1  2  2.0  NaN  2\n",
      "2  4  3.0  NaN  3\n",
      "3  4  NaN  4.0  4\n",
      "4  5  5.0  5.0  3\n",
      "\n",
      "transforming each value with the addition of 1:\n",
      "   A    B    C  D\n",
      "0  2  NaN  2.0  2\n",
      "1  3  3.0  NaN  3\n",
      "2  5  4.0  NaN  4\n",
      "3  5  NaN  5.0  5\n",
      "4  6  6.0  6.0  4\n"
     ]
    }
   ],
   "source": [
    "#data set generated by GEN AI\n",
    "data = {\n",
    "    'A': [1, 2, 4, 4, 5],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, np.nan, np.nan, 4, 5],\n",
    "    'D': [1, 2, 3, 4, 3]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Data Frame:\\n{df}\\n\")\n",
    "print(f\"transforming each value with the addition of 1:\\n{df.transform(lambda x: x+1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2c990-414f-47a2-8182-7f4212c6116f",
   "metadata": {},
   "source": [
    "9. Normalize a column using Min-Max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a30ba90b-56cc-423d-b4ff-3faf1cb440b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Age column:\n",
      "0      50\n",
      "1      31\n",
      "2      32\n",
      "3      21\n",
      "4      33\n",
      "       ..\n",
      "763    63\n",
      "764    27\n",
      "765    30\n",
      "766    47\n",
      "767    23\n",
      "Name: Age, Length: 768, dtype: int64\n",
      "\n",
      "Min-Max scaling of column Age:\n",
      "0      28.74\n",
      "1       9.74\n",
      "2      10.74\n",
      "3      -0.26\n",
      "4      11.74\n",
      "       ...  \n",
      "763    41.74\n",
      "764     5.74\n",
      "765     8.74\n",
      "766    25.74\n",
      "767     1.74\n",
      "Name: Age, Length: 768, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#dataframe\n",
    "df = pd.read_csv('C:/Users/faizr/Data-Science-Group-2---BWF---FAIZ-RAZA/Task 12/diabetes (1).csv')\n",
    "print(f\"Original Age column:\\n{df['Age']}\\n\")\n",
    "\n",
    "#min-max scaling is value-min/max-min\n",
    "min_max = (df['Age'] - df['Age'].min() / df['Age'].max() - df['Age'].min())\n",
    "print(f\"Min-Max scaling of column Age:\\n{round(min_max,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cb7c29-9d28-45b4-b0dc-a33d20770142",
   "metadata": {},
   "source": [
    "10. Standardize a column (z-score normalization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07bc1840-2f84-468f-9a1d-45d3790a1321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Age column:\n",
      "0      50\n",
      "1      31\n",
      "2      32\n",
      "3      21\n",
      "4      33\n",
      "       ..\n",
      "763    63\n",
      "764    27\n",
      "765    30\n",
      "766    47\n",
      "767    23\n",
      "Name: Age, Length: 768, dtype: int64\n",
      "\n",
      "Standardization of column Age:\n",
      "0      47.17\n",
      "1      28.17\n",
      "2      29.17\n",
      "3      18.17\n",
      "4      30.17\n",
      "       ...  \n",
      "763    60.17\n",
      "764    24.17\n",
      "765    27.17\n",
      "766    44.17\n",
      "767    20.17\n",
      "Name: Age, Length: 768, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#dataframe\n",
    "df = pd.read_csv('C:/Users/faizr/Data-Science-Group-2---BWF---FAIZ-RAZA/Task 12/diabetes (1).csv')\n",
    "print(f\"Original Age column:\\n{df['Age']}\\n\")\n",
    "\n",
    "#min-max scaling is value-mean/std\n",
    "min_max = (df['Age'] - df['Age'].mean() / df['Age'].std())\n",
    "print(f\"Standardization of column Age:\\n{round(min_max,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66160c12-83e1-4b80-8a86-d35e9e497018",
   "metadata": {},
   "source": [
    "11. Identify duplicate rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e618fab-96be-44af-8806-6b49a86dd775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2  Alice   30\n",
      "2   3    Bob   28\n",
      "3   4   Emma   22\n",
      "4   5   Jack   35\n",
      "5   2  Alice   30\n",
      "6   3    Bob   28\n",
      "7   4   Emma   22\n",
      "8   1   John   25\n",
      "9   6   Ryan   40\n",
      "\n",
      "Duplicate Rows:\n",
      "   ID   Name  Age\n",
      "5   2  Alice   30\n",
      "6   3    Bob   28\n",
      "7   4   Emma   22\n",
      "8   1   John   25\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 2, 3, 4, 1, 6],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Emma', 'Jack', 'Alice', 'Bob', 'Emma', 'John', 'Ryan'],\n",
    "    'Age': [25, 30, 28, 22, 35, 30, 28, 22, 25, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset:\\n{df}\\n\")\n",
    "#identify duplicate rows based on all columns\n",
    "dupli = df[df.duplicated()]\n",
    "print(f\"Duplicate Rows:\\n{dupli}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eea743f-7712-45ac-8814-39d8519879dd",
   "metadata": {},
   "source": [
    "12. Drop duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d13f6e8-88a3-4dde-b769-2a3b6708bc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2  Alice   30\n",
      "2   3    Bob   28\n",
      "3   4   Emma   22\n",
      "4   5   Jack   35\n",
      "5   2  Alice   30\n",
      "6   3    Bob   28\n",
      "7   4   Emma   22\n",
      "8   1   John   25\n",
      "9   6   Ryan   40\n",
      "\n",
      "Duplicate Rows Droped:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2  Alice   30\n",
      "2   3    Bob   28\n",
      "3   4   Emma   22\n",
      "4   5   Jack   35\n",
      "9   6   Ryan   40\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 2, 3, 4, 1, 6],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Emma', 'Jack', 'Alice', 'Bob', 'Emma', 'John', 'Ryan'],\n",
    "    'Age': [25, 30, 28, 22, 35, 30, 28, 22, 25, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset:\\n{df}\\n\")\n",
    "#identify duplicate rows based on all columns\n",
    "dupli = df.drop_duplicates()\n",
    "print(f\"Duplicate Rows Droped:\\n{dupli}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95adb75c-a0f3-4de5-b169-a8e78dadcdaf",
   "metadata": {},
   "source": [
    "13. Drop duplicate rows based on specific columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6ffb841a-4d12-4b5b-b773-6b9651fc04a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "    ID    Name  Age\n",
      "0    1    John   25\n",
      "1    2   Alice   30\n",
      "2    3     Bob   28\n",
      "3    4    Emma   22\n",
      "4    5    Jack   35\n",
      "5    2   Alice   30\n",
      "6    3     Bob   28\n",
      "7    4    Emma   22\n",
      "8    1    John   25\n",
      "9    6    Ryan   40\n",
      "10   1    John   25\n",
      "11   2  1Alice   30\n",
      "12   3    1Bob   28\n",
      "13   4   1Emma   22\n",
      "14   5   J1ack   35\n",
      "15   2  Al1ice   30\n",
      "16   3    B1ob   28\n",
      "17   4   Em1ma   22\n",
      "18   1   J1ohn   25\n",
      "19   6    Ryan   40\n",
      "\n",
      "Duplicate Rows Droped based on Age:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2  Alice   30\n",
      "2   3    Bob   28\n",
      "3   4   Emma   22\n",
      "4   5   Jack   35\n",
      "9   6   Ryan   40\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 2, 3, 4, 1, 6, 1, 2, 3, 4, 5, 2, 3, 4, 1, 6],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Emma', 'Jack', 'Alice', 'Bob', 'Emma', 'John', 'Ryan', 'John', '1Alice', '1Bob', '1Emma', 'J1ack', 'Al1ice', 'B1ob', 'Em1ma', 'J1ohn', 'Ryan'],\n",
    "    'Age': [25, 30, 28, 22, 35, 30, 28, 22, 25, 40, 25, 30, 28, 22, 35, 30, 28, 22, 25, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset:\\n{df}\\n\")\n",
    "#identify duplicate rows based on Age columns\n",
    "dupli = df.drop_duplicates('Age')\n",
    "print(f\"Duplicate Rows Droped based on Age:\\n{dupli}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c62758d-ae6c-4417-8a53-95792ef4758d",
   "metadata": {},
   "source": [
    "14. Convert all string values in a column to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b00ab56-1d45-44b5-b02b-17a37f9dafbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "   ID   Name  Age\n",
      "0   1   John   25\n",
      "1   2  Alice   30\n",
      "2   3    Bob   28\n",
      "3   4   Emma   22\n",
      "4   5   Jack   35\n",
      "5   2  Alice   30\n",
      "6   3    Bob   28\n",
      "7   4   Emma   22\n",
      "8   1   John   25\n",
      "9   6   Ryan   40\n",
      "\n",
      "Duplicate Rows Droped:\n",
      "0     john\n",
      "1    alice\n",
      "2      bob\n",
      "3     emma\n",
      "4     jack\n",
      "5    alice\n",
      "6      bob\n",
      "7     emma\n",
      "8     john\n",
      "9     ryan\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 2, 3, 4, 1, 6],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Emma', 'Jack', 'Alice', 'Bob', 'Emma', 'John', 'Ryan'],\n",
    "    'Age': [25, 30, 28, 22, 35, 30, 28, 22, 25, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset:\\n{df}\\n\")\n",
    "#lower the str\n",
    "print(f\"Duplicate Rows Droped:\\n{df['Name'].str.lower()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211996da-7268-4826-8d88-9d9ad148e250",
   "metadata": {},
   "source": [
    "15. Remove leading and trailing spaces from string values in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b48a5988-8170-438e-bb34-a30401829e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "   ID         Name  Age\n",
      "0   1         John   25\n",
      "1   2  Alice         30\n",
      "2   3          Bob   28\n",
      "3   4         Emma   22\n",
      "4   5         Jack   35\n",
      "5   2        Alice   30\n",
      "6   3          Bob   28\n",
      "7   4         Emma   22\n",
      "8   1         John   25\n",
      "9   6         Ryan   40\n",
      "\n",
      "Duplicate Rows Droped:\n",
      "0     John\n",
      "1    Alice\n",
      "2      Bob\n",
      "3     Emma\n",
      "4     Jack\n",
      "5    Alice\n",
      "6      Bob\n",
      "7     Emma\n",
      "8     John\n",
      "9     Ryan\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 2, 3, 4, 1, 6],\n",
    "    'Name': ['    John', 'Alice      ', 'Bob', 'Emma', 'Jack', 'Alice', 'Bob', 'Emma', 'John', 'Ryan'],\n",
    "    'Age': [25, 30, 28, 22, 35, 30, 28, 22, 25, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset:\\n{df}\\n\")\n",
    "#Remove the spaces\n",
    "print(f\"Duplicate Rows Droped:\\n{df['Name'].str.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c558c8b3-0bdd-4bbc-8500-7afb609117fd",
   "metadata": {},
   "source": [
    "16. Replace a specific substring in a column with another substring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bd0b249c-1265-4bcd-922f-32762c0b70d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "0     John\n",
      "1    Alice\n",
      "2      Bob\n",
      "3     Emma\n",
      "4     Jack\n",
      "5    Alice\n",
      "6      Bob\n",
      "7     Emma\n",
      "8     John\n",
      "9     Ryan\n",
      "Name: Name, dtype: object\n",
      "\n",
      "Replace the John with faiz: \n",
      "0     Faiz\n",
      "1    Alice\n",
      "2      Bob\n",
      "3     Emma\n",
      "4     Jack\n",
      "5    Alice\n",
      "6      Bob\n",
      "7     Emma\n",
      "8     Faiz\n",
      "9     Ryan\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 2, 3, 4, 1, 6],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Emma', 'Jack', 'Alice', 'Bob', 'Emma', 'John', 'Ryan'],\n",
    "    'Age': [25, 30, 28, 22, 35, 30, 28, 22, 25, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset:\\n{df['Name']}\\n\")\n",
    "#lower the str\n",
    "rep = df['Name'].replace('John', 'Faiz')\n",
    "print(f\"Replace the John with faiz: \\n{rep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d06694-d92e-4b95-a6fd-d637de3b451b",
   "metadata": {},
   "source": [
    "17. Extract a substring from each value in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bb6ce270-4edb-45a7-b875-9e6c4864187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "0     John\n",
      "1    Alice\n",
      "2      Bob\n",
      "3     Emma\n",
      "4     Jack\n",
      "5    Alice\n",
      "6      Bob\n",
      "7     Emma\n",
      "8     John\n",
      "9     Ryan\n",
      "Name: Name, dtype: object\n",
      "\n",
      "Extracted the substring from the columnn: \n",
      "0    Jo\n",
      "1    Al\n",
      "2    Bo\n",
      "3    Em\n",
      "4    Ja\n",
      "5    Al\n",
      "6    Bo\n",
      "7    Em\n",
      "8    Jo\n",
      "9    Ry\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'ID': [1, 2, 3, 4, 5, 2, 3, 4, 1, 6],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Emma', 'Jack', 'Alice', 'Bob', 'Emma', 'John', 'Ryan'],\n",
    "    'Age': [25, 30, 28, 22, 35, 30, 28, 22, 25, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset:\\n{df['Name']}\\n\")\n",
    "#lower the str\n",
    "rep = df['Name'].str[:2]\n",
    "print(f\"Extracted the substring from the columnn: \\n{rep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71779604-45ab-4cc0-be36-f09da122983f",
   "metadata": {},
   "source": [
    "18. Convert a column to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1d1cda2b-76d4-4935-93c2-cb6c65aba6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Date    6 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 180.0+ bytes\n",
      "The data type before: \n",
      "None\n",
      "\n",
      "The data type After: \n",
      "0   2022-01-01 10:00:00\n",
      "1   2022-01-15 12:30:00\n",
      "2   2022-02-20 14:45:00\n",
      "3   2022-03-12 16:00:00\n",
      "4   2022-04-05 10:15:00\n",
      "5   2022-05-18 11:30:00\n",
      "Name: Date, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Date': ['2022-01-01 10:00:00', '2022-01-15 12:30:00', '2022-02-20 14:45:00',\n",
    "             '2022-03-12 16:00:00', '2022-04-05 10:15:00', '2022-05-18 11:30:00']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"The data type before: \\n{df.info()}\\n\")\n",
    "print(f\"The data type After: \\n{pd.to_datetime(df['Date'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ab076-d643-47ea-b4b2-0260c17e8b2a",
   "metadata": {},
   "source": [
    "19. Extract year, month, and day from a datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fb2e3b49-388c-4b1d-a810-d1b696ff3ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Data: \n",
      "                 Date\n",
      "0 2022-01-01 10:00:00\n",
      "1 2022-01-15 12:30:00\n",
      "2 2022-02-20 14:45:00\n",
      "3 2022-03-12 16:00:00\n",
      "4 2022-04-05 10:15:00\n",
      "5 2022-05-18 11:30:00\n",
      "\n",
      "Extracted the Year, Month and day:\n",
      "                 Date  Year  Month  day\n",
      "0 2022-01-01 10:00:00  2022      1    1\n",
      "1 2022-01-15 12:30:00  2022      1   15\n",
      "2 2022-02-20 14:45:00  2022      2   20\n",
      "3 2022-03-12 16:00:00  2022      3   12\n",
      "4 2022-04-05 10:15:00  2022      4    5\n",
      "5 2022-05-18 11:30:00  2022      5   18\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Date': ['2022-01-01 10:00:00', '2022-01-15 12:30:00', '2022-02-20 14:45:00',\n",
    "             '2022-03-12 16:00:00', '2022-04-05 10:15:00', '2022-05-18 11:30:00']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(f\"Old Data: \\n{df}\\n\")\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "print(f\"Extracted the Year, Month and day:\\n{df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be28f83e-ce34-4e62-8e06-9089ade14718",
   "metadata": {},
   "source": [
    "20. Filter rows based on a date range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "203fd3f0-ae23-4ca4-900e-52dff7d563b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Data: \n",
      "  typeofaction  sourceid  destinationid  amountofmoney                Date  \\\n",
      "0      cash-in     30105          28942         494528 2019-07-19 14:40:00   \n",
      "1      cash-in     30105           8692         494528 2019-05-17 14:57:00   \n",
      "2      cash-in     30105          60094         494528 2019-07-20 13:20:00   \n",
      "3      cash-in     30105          20575         494528 2019-07-03 14:15:00   \n",
      "4      cash-in     30105          45938         494528 2019-05-26 10:40:00   \n",
      "\n",
      "   isfraud typeoffraud  \n",
      "0        1       type1  \n",
      "1        1       type1  \n",
      "2        1       type1  \n",
      "3        1       type1  \n",
      "4        1       type1  \n",
      "\n",
      "Extracted the Year, Month and day:\n",
      "  typeofaction  sourceid  destinationid  amountofmoney                Date  \\\n",
      "0      cash-in     30105          28942         494528 2019-07-19 14:40:00   \n",
      "1      cash-in     30105           8692         494528 2019-05-17 14:57:00   \n",
      "2      cash-in     30105          60094         494528 2019-07-20 13:20:00   \n",
      "3      cash-in     30105          20575         494528 2019-07-03 14:15:00   \n",
      "4      cash-in     30105          45938         494528 2019-05-26 10:40:00   \n",
      "\n",
      "   isfraud typeoffraud  Year  Month  day  \n",
      "0        1       type1  2019      7   19  \n",
      "1        1       type1  2019      5   17  \n",
      "2        1       type1  2019      7   20  \n",
      "3        1       type1  2019      7    3  \n",
      "4        1       type1  2019      5   26  \n",
      "\n",
      "Filtered Dataset:\n",
      "    typeofaction  sourceid  destinationid  amountofmoney                Date  \\\n",
      "61       cash-in     92735          83840         306537 2019-07-10 12:19:00   \n",
      "143      cash-in     37177          33994         362164 2019-07-10 15:04:00   \n",
      "213      cash-in     39284          29925         274171 2019-07-10 10:07:00   \n",
      "285      cash-in     24041          46541         322413 2019-07-10 13:44:00   \n",
      "670     transfer     52566           8509        6654803 2019-07-10 15:55:00   \n",
      "\n",
      "     isfraud typeoffraud  Year  Month  day  \n",
      "61         1       type1  2019      7   10  \n",
      "143        1       type1  2019      7   10  \n",
      "213        1       type1  2019      7   10  \n",
      "285        1       type1  2019      7   10  \n",
      "670        1       type2  2019      7   10  \n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "df = pd.read_csv('ML.csv')\n",
    "#Renaming the columnn name \n",
    "df.rename(columns = {'date': 'Date'}, inplace = True)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "print(f\"Old Data: \\n{df.head()}\\n\")\n",
    "\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "\n",
    "print(f\"Extracted the Year, Month and day:\\n{df.head()}\\n\") #extracted years, months and day\n",
    "\n",
    "print(f\"Filtered Dataset:\\n{df[(df['Month'] == 7) & (df['day'] == 10)].head()}\") #filtered dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f453e-dee3-4dc9-845e-94dc9b513285",
   "metadata": {},
   "source": [
    "21. Convert a categorical column to numerical using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d32f004c-7857-4470-a0ba-4236048c9c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first rows of df:\n",
      "  typeofaction  sourceid  destinationid  amountofmoney                Date  \\\n",
      "0      cash-in     30105          28942         494528 2019-07-19 14:40:00   \n",
      "1      cash-in     30105           8692         494528 2019-05-17 14:57:00   \n",
      "2      cash-in     30105          60094         494528 2019-07-20 13:20:00   \n",
      "3      cash-in     30105          20575         494528 2019-07-03 14:15:00   \n",
      "4      cash-in     30105          45938         494528 2019-05-26 10:40:00   \n",
      "\n",
      "   isfraud typeoffraud  Year  Month  day  \n",
      "0        1       type1  2019      7   19  \n",
      "1        1       type1  2019      5   17  \n",
      "2        1       type1  2019      7   20  \n",
      "3        1       type1  2019      7    3  \n",
      "4        1       type1  2019      5   26  \n",
      "\n",
      "One hot endoing of typeofaction columnn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sourceid</th>\n",
       "      <th>destinationid</th>\n",
       "      <th>amountofmoney</th>\n",
       "      <th>Date</th>\n",
       "      <th>isfraud</th>\n",
       "      <th>typeoffraud</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>day</th>\n",
       "      <th>typeofaction_cash-in</th>\n",
       "      <th>typeofaction_transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30105</td>\n",
       "      <td>28942</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-07-19 14:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30105</td>\n",
       "      <td>8692</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-05-17 14:57:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30105</td>\n",
       "      <td>60094</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-07-20 13:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30105</td>\n",
       "      <td>20575</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-07-03 14:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30105</td>\n",
       "      <td>45938</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-05-26 10:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sourceid  destinationid  amountofmoney                Date  isfraud  \\\n",
       "0     30105          28942         494528 2019-07-19 14:40:00        1   \n",
       "1     30105           8692         494528 2019-05-17 14:57:00        1   \n",
       "2     30105          60094         494528 2019-07-20 13:20:00        1   \n",
       "3     30105          20575         494528 2019-07-03 14:15:00        1   \n",
       "4     30105          45938         494528 2019-05-26 10:40:00        1   \n",
       "\n",
       "  typeoffraud  Year  Month  day  typeofaction_cash-in  typeofaction_transfer  \n",
       "0       type1  2019      7   19                     1                      0  \n",
       "1       type1  2019      5   17                     1                      0  \n",
       "2       type1  2019      7   20                     1                      0  \n",
       "3       type1  2019      7    3                     1                      0  \n",
       "4       type1  2019      5   26                     1                      0  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df is already loaded\n",
    "print(f\"first rows of df:\\n{df.head()}\\n\")\n",
    "#one hot encoding usnig pandas\n",
    "print(\"One hot endoing of typeofaction columnn\")\n",
    "pd.get_dummies(df, columns=['typeofaction'],dtype=int).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5eb73-c6fc-45a6-a567-76214c5788f9",
   "metadata": {},
   "source": [
    "22. Convert a categorical column to numerical using label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "79486895-f197-48f2-b048-4944bb7e8000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first rows of df:\n",
      "  typeofaction  sourceid  destinationid  amountofmoney                Date  \\\n",
      "0      cash-in     30105          28942         494528 2019-07-19 14:40:00   \n",
      "1      cash-in     30105           8692         494528 2019-05-17 14:57:00   \n",
      "2      cash-in     30105          60094         494528 2019-07-20 13:20:00   \n",
      "3      cash-in     30105          20575         494528 2019-07-03 14:15:00   \n",
      "4      cash-in     30105          45938         494528 2019-05-26 10:40:00   \n",
      "\n",
      "   isfraud typeoffraud  Year  Month  day  \n",
      "0        1       type1  2019      7   19  \n",
      "1        1       type1  2019      5   17  \n",
      "2        1       type1  2019      7   20  \n",
      "3        1       type1  2019      7    3  \n",
      "4        1       type1  2019      5   26  \n",
      "\n",
      "label endoing of typeofaction columnn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typeofaction</th>\n",
       "      <th>sourceid</th>\n",
       "      <th>destinationid</th>\n",
       "      <th>amountofmoney</th>\n",
       "      <th>Date</th>\n",
       "      <th>isfraud</th>\n",
       "      <th>typeoffraud</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30105</td>\n",
       "      <td>28942</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-07-19 14:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>30105</td>\n",
       "      <td>8692</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-05-17 14:57:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>30105</td>\n",
       "      <td>60094</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-07-20 13:20:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30105</td>\n",
       "      <td>20575</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-07-03 14:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>30105</td>\n",
       "      <td>45938</td>\n",
       "      <td>494528</td>\n",
       "      <td>2019-05-26 10:40:00</td>\n",
       "      <td>1</td>\n",
       "      <td>type1</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>1</td>\n",
       "      <td>14945</td>\n",
       "      <td>43793</td>\n",
       "      <td>106907</td>\n",
       "      <td>2019-03-29 14:53:00</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>1</td>\n",
       "      <td>9532</td>\n",
       "      <td>43793</td>\n",
       "      <td>106907</td>\n",
       "      <td>2019-04-13 13:19:00</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>1</td>\n",
       "      <td>27332</td>\n",
       "      <td>43793</td>\n",
       "      <td>106907</td>\n",
       "      <td>2019-05-10 09:34:00</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>1</td>\n",
       "      <td>32685</td>\n",
       "      <td>43793</td>\n",
       "      <td>106907</td>\n",
       "      <td>2019-07-08 12:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>1</td>\n",
       "      <td>26390</td>\n",
       "      <td>43793</td>\n",
       "      <td>106907</td>\n",
       "      <td>2019-03-25 13:52:00</td>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2340 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      typeofaction  sourceid  destinationid  amountofmoney  \\\n",
       "0                0     30105          28942         494528   \n",
       "1                0     30105           8692         494528   \n",
       "2                0     30105          60094         494528   \n",
       "3                0     30105          20575         494528   \n",
       "4                0     30105          45938         494528   \n",
       "...            ...       ...            ...            ...   \n",
       "2335             1     14945          43793         106907   \n",
       "2336             1      9532          43793         106907   \n",
       "2337             1     27332          43793         106907   \n",
       "2338             1     32685          43793         106907   \n",
       "2339             1     26390          43793         106907   \n",
       "\n",
       "                    Date  isfraud typeoffraud  Year  Month  day  \n",
       "0    2019-07-19 14:40:00        1       type1  2019      7   19  \n",
       "1    2019-05-17 14:57:00        1       type1  2019      5   17  \n",
       "2    2019-07-20 13:20:00        1       type1  2019      7   20  \n",
       "3    2019-07-03 14:15:00        1       type1  2019      7    3  \n",
       "4    2019-05-26 10:40:00        1       type1  2019      5   26  \n",
       "...                  ...      ...         ...   ...    ...  ...  \n",
       "2335 2019-03-29 14:53:00        0        none  2019      3   29  \n",
       "2336 2019-04-13 13:19:00        0        none  2019      4   13  \n",
       "2337 2019-05-10 09:34:00        0        none  2019      5   10  \n",
       "2338 2019-07-08 12:20:00        0        none  2019      7    8  \n",
       "2339 2019-03-25 13:52:00        0        none  2019      3   25  \n",
       "\n",
       "[2340 rows x 10 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df is already loaded\n",
    "print(f\"first rows of df:\\n{df.head()}\\n\")\n",
    "#one hot encoding usnig pandas\n",
    "df['typeofaction']= df['typeofaction'].map({'cash-in':0, 'transfer':1})\n",
    "print(\"label endoing of typeofaction columnn\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94177189-097a-4ad5-9ecf-01e79e2cf5c3",
   "metadata": {},
   "source": [
    "23. Group values in a categorical column and create a new column with grouped categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e75ad035-4332-4b7b-84b3-ecd7253ad19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "    color  value\n",
      "0     red     10\n",
      "1    pink     20\n",
      "2    blue     30\n",
      "3   green     40\n",
      "4     red     50\n",
      "5    pink     60\n",
      "6    blue     70\n",
      "7   green     80\n",
      "8  yellow     90\n",
      "9  purple    100\n",
      "\n",
      "created a group of different colors:\n",
      "    color  value Colour group\n",
      "0     red     10         dark\n",
      "1    pink     20        light\n",
      "2    blue     30         dark\n",
      "3   green     40        light\n",
      "4     red     50         dark\n",
      "5    pink     60        light\n",
      "6    blue     70         dark\n",
      "7   green     80        light\n",
      "8  yellow     90        light\n",
      "9  purple    100         dark\n"
     ]
    }
   ],
   "source": [
    "#dataset generated by gen AI\n",
    "data = {\n",
    "    'color': ['red', 'pink', 'blue', 'green', 'red', 'pink', 'blue', 'green', 'yellow', 'purple'],\n",
    "    'value': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Dataset:\\n{df}\\n\")\n",
    "\n",
    "df['Colour group'] = df.color.map({'red':'dark', 'pink':'light', 'blue':'dark', 'green':'light', 'yellow': 'light', 'purple': 'dark'})\n",
    "print(f\"created a group of different colors:\\n{df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db291d-c8ac-42d6-a8bb-20c1fc890296",
   "metadata": {},
   "source": [
    "24. Merge two DataFrames based on a common column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d278860d-b09f-4c03-8c4f-6cf065ca41bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>total</th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>100</td>\n",
       "      <td>John</td>\n",
       "      <td>john@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>150</td>\n",
       "      <td>John</td>\n",
       "      <td>john@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>200</td>\n",
       "      <td>Mary</td>\n",
       "      <td>mary@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-05</td>\n",
       "      <td>250</td>\n",
       "      <td>Mary</td>\n",
       "      <td>mary@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>300</td>\n",
       "      <td>David</td>\n",
       "      <td>david@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>350</td>\n",
       "      <td>David</td>\n",
       "      <td>david@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>400</td>\n",
       "      <td>Emily</td>\n",
       "      <td>emily@example.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>500</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>sarah@example.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  order_date  total   name              email\n",
       "0        1  2022-01-01    100   John   john@example.com\n",
       "1        1  2022-02-01    150   John   john@example.com\n",
       "2        2  2022-01-05    200   Mary   mary@example.com\n",
       "3        2  2022-02-05    250   Mary   mary@example.com\n",
       "4        3  2022-01-10    300  David  david@example.com\n",
       "5        3  2022-02-10    350  David  david@example.com\n",
       "6        4  2022-01-15    400  Emily  emily@example.com\n",
       "7        5  2022-01-20    500  Sarah  sarah@example.com"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset generated by gen AI\n",
    "data = {\n",
    "    'user_id': [1, 2, 3, 4, 5, 1, 2, 3],\n",
    "    'order_date': ['2022-01-01', '2022-01-05', '2022-01-10', '2022-01-15', '2022-01-20', '2022-02-01', '2022-02-05', '2022-02-10'],\n",
    "    'total': [100, 200, 300, 400, 500, 150, 250, 350]\n",
    "}\n",
    "data2 = {\n",
    "    'user_id': [1, 2, 3, 4, 5],\n",
    "    'name': ['John', 'Mary', 'David', 'Emily', 'Sarah'],\n",
    "    'email': ['john@example.com', 'mary@example.com', 'david@example.com', 'emily@example.com', 'sarah@example.com']\n",
    "}\n",
    "df_orders = pd.DataFrame(data)\n",
    "df_users = pd.DataFrame(data2)\n",
    "\n",
    "#merge on the UID of user_id\n",
    "pd.merge(df_orders, df_users, on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86232df4-2122-4f0b-90d6-cf0673eb9626",
   "metadata": {},
   "source": [
    "25. Concatenate two DataFrames vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "23f3b530-abb2-4c66-a4b4-402b0da94cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation of the dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>product</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North</td>\n",
       "      <td>A</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North</td>\n",
       "      <td>B</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North</td>\n",
       "      <td>C</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North</td>\n",
       "      <td>D</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North</td>\n",
       "      <td>E</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South</td>\n",
       "      <td>F</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South</td>\n",
       "      <td>G</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South</td>\n",
       "      <td>H</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South</td>\n",
       "      <td>I</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South</td>\n",
       "      <td>J</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region product  sales\n",
       "0  North       A    100\n",
       "1  North       B    200\n",
       "2  North       C    300\n",
       "3  North       D    400\n",
       "4  North       E    500\n",
       "0  South       F    600\n",
       "1  South       G    700\n",
       "2  South       H    800\n",
       "3  South       I    900\n",
       "4  South       J   1000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'region': ['North'] * 5,\n",
    "    'product': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'sales': [100, 200, 300, 400, 500]\n",
    "}\n",
    "data2 = {\n",
    "    'region': ['South'] * 5,\n",
    "    'product': ['F', 'G', 'H', 'I', 'J'],\n",
    "    'sales': [600, 700, 800, 900, 1000]\n",
    "}\n",
    "df_north = pd.DataFrame(data)\n",
    "df_south = pd.DataFrame(data2)\n",
    "#concatenation of the dataset\n",
    "print(\"Concatenation of the dataset: \")\n",
    "pd.concat([df_north, df_south])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e3b940-0d03-4699-860a-e075ec78297d",
   "metadata": {},
   "source": [
    "26. Concatenate two DataFrames horizontally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f80216fc-9423-4cf1-8f81-924dddfa75dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation of the dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>product</th>\n",
       "      <th>sales</th>\n",
       "      <th>region</th>\n",
       "      <th>product</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>North</td>\n",
       "      <td>A</td>\n",
       "      <td>100</td>\n",
       "      <td>South</td>\n",
       "      <td>F</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>North</td>\n",
       "      <td>B</td>\n",
       "      <td>200</td>\n",
       "      <td>South</td>\n",
       "      <td>G</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>North</td>\n",
       "      <td>C</td>\n",
       "      <td>300</td>\n",
       "      <td>South</td>\n",
       "      <td>H</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North</td>\n",
       "      <td>D</td>\n",
       "      <td>400</td>\n",
       "      <td>South</td>\n",
       "      <td>I</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>North</td>\n",
       "      <td>E</td>\n",
       "      <td>500</td>\n",
       "      <td>South</td>\n",
       "      <td>J</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  region product  sales region product  sales\n",
       "0  North       A    100  South       F    600\n",
       "1  North       B    200  South       G    700\n",
       "2  North       C    300  South       H    800\n",
       "3  North       D    400  South       I    900\n",
       "4  North       E    500  South       J   1000"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'region': ['North'] * 5,\n",
    "    'product': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'sales': [100, 200, 300, 400, 500]\n",
    "}\n",
    "data2 = {\n",
    "    'region': ['South'] * 5,\n",
    "    'product': ['F', 'G', 'H', 'I', 'J'],\n",
    "    'sales': [600, 700, 800, 900, 1000]\n",
    "}\n",
    "df_north = pd.DataFrame(data)\n",
    "df_south = pd.DataFrame(data2)\n",
    "#concatenation of the dataset\n",
    "print(\"Concatenation of the dataset: \")\n",
    "pd.concat([df_north, df_south],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa6311e-4052-48d7-8ad9-93d405bf48f5",
   "metadata": {},
   "source": [
    "27. Create a new column based on existing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "0ec0127f-f4eb-45c1-8d43-f8ef4229e3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenation of the dataset:\n",
      "   region product  sales region product  sales\n",
      "0  North       A    100  South       F    600\n",
      "1  North       B    200  South       G    700\n",
      "2  North       C    300  South       H    800\n",
      "3  North       D    400  South       I    900\n",
      "4  North       E    500  South       J   1000\\ \n",
      "new dataset: \n",
      "  region product  sales region product  sales  Total_sales\n",
      "0  North       A    100  South       F    600          700\n",
      "1  North       B    200  South       G    700          900\n",
      "2  North       C    300  South       H    800         1100\n",
      "3  North       D    400  South       I    900         1300\n",
      "4  North       E    500  South       J   1000         1500\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'region': ['North'] * 5,\n",
    "    'product': ['A', 'B', 'C', 'D', 'E'],\n",
    "    'sales': [100, 200, 300, 400, 500]\n",
    "}\n",
    "data2 = {\n",
    "    'region': ['South'] * 5,\n",
    "    'product': ['F', 'G', 'H', 'I', 'J'],\n",
    "    'sales': [600, 700, 800, 900, 1000]\n",
    "}\n",
    "df_north = pd.DataFrame(data)\n",
    "df_south = pd.DataFrame(data2)\n",
    "#concatenation of the dataset\n",
    "\n",
    "df = pd.concat([df_north, df_south],axis=1)\n",
    "print(f\"Concatenation of the dataset:\\n {df}\\ \")\n",
    "df['Total_sales'] = df.iloc[:,2]+df.iloc[:,5]\n",
    "print(f\"new dataset: \\n{df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1884af-5c12-4d28-a823-037ee95d6ed4",
   "metadata": {},
   "source": [
    "28. Discretize a continuous column into bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "09c7a2e0-5b3f-45f0-8e24-17f2c0f3b910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (10, 20]\n",
       "1    (20, 30]\n",
       "2    (20, 30]\n",
       "3    (30, 40]\n",
       "4    (30, 40]\n",
       "5    (40, 50]\n",
       "6    (40, 50]\n",
       "7    (50, 60]\n",
       "8    (50, 60]\n",
       "9    (60, 70]\n",
       "Name: values, dtype: category\n",
       "Categories (7, interval[int64, right]): [(0, 10] < (10, 20] < (20, 30] < (30, 40] < (40, 50] < (50, 60] < (60, 70]]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# generate a sample dataset\n",
    "data = {'values': [18, 25, 30, 35, 40, 45, 50, 55, 60, 65]}\n",
    "df = pd.DataFrame(data)\n",
    "#bins create of the continous value\n",
    "pd.cut(df['values'], bins = [0,10,20,30,40,50,60,70])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adcc308-5f8f-406c-800f-ca63ad41a518",
   "metadata": {},
   "source": [
    "29. Create polynomial features from existing numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "88d869ce-f892-4d29-be79-ca4de3c91064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial of features with poly 3:\n",
      "   values  Poly of 3\n",
      "0      18       5832\n",
      "1      25      15625\n",
      "2      30      27000\n",
      "3      35      42875\n",
      "4      40      64000\n",
      "5      45      91125\n",
      "6      50     125000\n",
      "7      55     166375\n",
      "8      60     216000\n",
      "9      65     274625\n"
     ]
    }
   ],
   "source": [
    "#df is already defined\n",
    "#apply polynomial features\n",
    "df['Poly of 3'] = df.iloc[:,0] ** 3\n",
    "print(f\"Polynomial of features with poly 3:\\n{df}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2ca6f-341d-43d6-89e6-fb68ed21fe47",
   "metadata": {},
   "source": [
    "# Practicle Application\n",
    "# Data Preprocessor\n",
    "\n",
    "A command-line application for preprocessing datasets using pandas. Perform various tasks such as identifying missing values, dropping rows/columns, filling missing values, transforming data, filtering, and aggregating. Save the processed data to a new file.\n",
    "\n",
    "## Features:\n",
    "\n",
    "* Load dataset from CSV or Excel file\n",
    "* Identify missing values\n",
    "* Drop rows/columns with missing values\n",
    "* Fill missing values with a specific value\n",
    "* Transform data (e.g., convert data types, apply functions)\n",
    "* Filter data based on specific conditions\n",
    "* Aggregate data (e.g., group by, calculate mean)\n",
    "* Save processed data to a new file\n",
    "\n",
    "## Usage:\n",
    "\n",
    "* Load the application and select a task to perform\n",
    "* Follow the prompts to complete the task\n",
    "* Save the processed data to a new file\n",
    "\n",
    "## Benefits:\n",
    "\n",
    "* Easy to use command-line interface\n",
    "* Perform various data preprocessing tasks in one application\n",
    "* Save time and increase productivity\n",
    "* Output processed data in a new file for further analysis or use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a767358a-5e52-4fac-89ab-1aee73aa5b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Country</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>USA</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mary</td>\n",
       "      <td>31</td>\n",
       "      <td>Female</td>\n",
       "      <td>UK</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>Australia</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emily</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>Canada</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sarah</td>\n",
       "      <td>28</td>\n",
       "      <td>Female</td>\n",
       "      <td>Germany</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Michael</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>USA</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lisa</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>UK</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Paul</td>\n",
       "      <td>38</td>\n",
       "      <td>Male</td>\n",
       "      <td>Australia</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Laura</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Canada</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kevin</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>Germany</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age  Gender    Country  Score\n",
       "0     John   25    Male        USA     80\n",
       "1     Mary   31  Female         UK     90\n",
       "2    David   42    Male  Australia     70\n",
       "3    Emily   35  Female     Canada     85\n",
       "4    Sarah   28  Female    Germany     95\n",
       "5  Michael   40    Male        USA     75\n",
       "6     Lisa   29  Female         UK     80\n",
       "7     Paul   38    Male  Australia     85\n",
       "8    Laura   32  Female     Canada     90\n",
       "9    Kevin   45    Male    Germany     70"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5f4aa41e-b568-47d6-af55-79e71dee06ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name       0\n",
      "Age        0\n",
      "Gender     0\n",
      "Country    0\n",
      "Score      0\n",
      "dtype: int64\n",
      "      Name  Age  Gender    Country  Score\n",
      "0     John   25    Male        USA     80\n",
      "1     Mary   31  Female         UK     90\n",
      "2    David   42    Male  Australia     70\n",
      "3    Emily   35  Female     Canada     85\n",
      "4    Sarah   28  Female    Germany     95\n",
      "5  Michael   40    Male        USA     75\n",
      "6     Lisa   29  Female         UK     80\n",
      "7     Paul   38    Male  Australia     85\n",
      "8    Laura   32  Female     Canada     90\n",
      "9    Kevin   45    Male    Germany     70\n",
      "      Name  Age  Gender    Country  Score\n",
      "0     John   25    Male        USA     80\n",
      "1     Mary   31  Female         UK     90\n",
      "2    David   42    Male  Australia     70\n",
      "3    Emily   35  Female     Canada     85\n",
      "4    Sarah   28  Female    Germany     95\n",
      "5  Michael   40    Male        USA     75\n",
      "6     Lisa   29  Female         UK     80\n",
      "7     Paul   38    Male  Australia     85\n",
      "8    Laura   32  Female     Canada     90\n",
      "9    Kevin   45    Male    Germany     70\n",
      "      Name  Age  Gender    Country  Score\n",
      "0     John   25    Male        USA     80\n",
      "1     Mary   31  Female         UK     90\n",
      "2    David   42    Male  Australia     70\n",
      "3    Emily   35  Female     Canada     85\n",
      "4    Sarah   28  Female    Germany     95\n",
      "5  Michael   40    Male        USA     75\n",
      "6     Lisa   29  Female         UK     80\n",
      "7     Paul   38    Male  Australia     85\n",
      "8    Laura   32  Female     Canada     90\n",
      "9    Kevin   45    Male    Germany     70\n",
      "      Name  Age  Gender    Country  Score\n",
      "1     Mary   31  Female         UK     90\n",
      "2    David   42    Male  Australia     70\n",
      "3    Emily   35  Female     Canada     85\n",
      "5  Michael   40    Male        USA     75\n",
      "7     Paul   38    Male  Australia     85\n",
      "8    Laura   32  Female     Canada     90\n",
      "9    Kevin   45    Male    Germany     70\n",
      "Gender\n",
      "Female    88.0\n",
      "Male      76.0\n",
      "Name: Score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Identify missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "print(df)\n",
    "\n",
    "# Drop columns with missing values\n",
    "df = df.dropna(axis=1)\n",
    "print(df)\n",
    "\n",
    "# Fill missing values with a specific value\n",
    "df = df.fillna('Unknown')\n",
    "print(df)\n",
    "\n",
    "# Filter data based on specific conditions\n",
    "filtered_df = df[df['Age'] > 30]\n",
    "print(filtered_df)\n",
    "\n",
    "# Aggregate data by grouping and applying functions\n",
    "grouped_df = df.groupby('Gender')['Score'].mean()\n",
    "print(grouped_df)\n",
    "\n",
    "# Save processed data to a new CSV file\n",
    "df.to_csv('processed_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9f637-e82d-457b-bfe8-c370d764143e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
