{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4faff7-74ad-4e85-b939-3c7426bfaa35",
   "metadata": {},
   "source": [
    "# Natural Language Preprocessing\n",
    "\n",
    "Natural language processing (NLP) is a branch of artificial intelligence (AI) that enables computers to comprehend, generate, and manipulate human language. Natural language processing has the ability to interrogate the data with natural language text or voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "61f76092-858f-493c-9ec5-4dee2db188b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a5fa2b21-619e-4a85-8227-6d067cb3bbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\""
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be19011-6964-4b9b-bdea-b2a1ecda1bfe",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "1. ### To LowerCase\n",
    "   Python is a case sensitive programming language. for python `A` and `a` are different things. So, we convert all to the lower case to avoid the confusion for python and treat them as same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "73bc3b96-0290-47d6-b38e-28a97871ea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Lower Text: \n",
      "heyi there! have yu visited https://example.com recently? it's amazing! i bought 2 new gadgets from their sale last week (crazy deals!). the total cost was $199.99â€”what a bargain! ðŸ˜Š but iâ€™m a bit concerned about my data privacy... ðŸ¤” are they really protecting my information? by the way, do you know if johnâ€™s email is john.doe123@example.com? i need to contact him asap. see you at 5:00 pm tomorrow!\n"
     ]
    }
   ],
   "source": [
    "text_lower = text.lower()\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Lower Text: \\n{text_lower}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6723f-ab30-48ed-90c5-cd8c7774d9c2",
   "metadata": {},
   "source": [
    "2. ### Handling URLs\n",
    "   URLs is unnecessary while trainning the nlp model. they don't have any meaning in the text. so we remove it. to remove the redundant data, to reduce the computational resource and to make the model more better on perrformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8f3994b4-b073-4cb3-ac51-70e3c67b436f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified Text: \n",
      "Heyi there! Have yu visited example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "#regex is used for this purpose, as it have the compile method in it's function\n",
    "url_format = re.compile('https://')\n",
    "\n",
    "def url_handle(text):\n",
    "    return url_format.sub('', text)\n",
    "\n",
    "URLHandle = url_handle(text)\n",
    "\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified Text: \\n{URLHandle}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14146906-b7c4-4d71-82f7-98c02ce2d627",
   "metadata": {},
   "source": [
    "3. ### Non-Word/Non-Whitespace\n",
    "   Non-word and Non_whitespace, it's crucial to remove them that are considerd as words or whitespace\n",
    "\n",
    "- `\\w:` Matches any word character (equivalent to `[a-zA-Z0-9_]`).\n",
    "- `\\s:` Matches any whitespace character (spaces, tabs, line breaks).\n",
    "- `^:` The caret (^) inside the square brackets negates the character class, meaning it matches anything that is NOT a word character or a whitespace character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2cd3a074-fb09-4f2e-b172-19db58c9718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "This is the White Text in the Start!!\n"
     ]
    }
   ],
   "source": [
    "whiteText = \"     This is the White Text in the Start!!  \"\n",
    "noWhiteText = whiteText.strip()\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{noWhiteText}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc033f2-e61e-4fd8-9224-7e30dce6389e",
   "metadata": {},
   "source": [
    "4. ### Digits\n",
    "    In the text, the numerical doesn't hold the much signinficance, so in most cases while training the model we remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "1eda072d-8bcb-4768-abb8-306e80469dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought  new gadgets from their sale last week (crazy deals!). The total cost was $.â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe@example.com? I need to contact him ASAP. See you at : PM tomorrow!\n"
     ]
    }
   ],
   "source": [
    "noDigits = re.sub(r'\\d', '', text)\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{noDigits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d311da-e259-4e95-bba5-76aadb43b583",
   "metadata": {},
   "source": [
    "5. ### Tokenization\n",
    "    Tokenization is the process of breaking down large blocks of text into smallers, for more manageable block units, eog. a lenctence is divided into small units with each word as itself a unit. It happes in NLP, so we can get the more accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "89af79c9-1ef7-4a48-bbe4-0879a6917aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\faizr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "563d4283-568f-4fce-8bca-ff6e2733335c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Tokens: \n",
      "['Heyi', 'there', '!', 'Have', 'yu', 'visited', 'https', ':', '//example.com', 'recently', '?', 'It', \"'s\", 'amazing', '!', 'I', 'bought', '2', 'new', 'gadgets', 'from', 'their', 'sale', 'last', 'week', '(', 'crazy', 'deals', '!', ')', '.', 'The', 'total', 'cost', 'was', '$', '199.99â€”what', 'a', 'bargain', '!', 'ðŸ˜Š', 'But', 'I', 'â€™', 'm', 'a', 'bit', 'concerned', 'about', 'my', 'data', 'privacy', '...', 'ðŸ¤”', 'Are', 'they', 'really', 'protecting', 'my', 'information', '?', 'By', 'the', 'way', ',', 'do', 'you', 'know', 'if', 'John', 'â€™', 's', 'email', 'is', 'john.doe123', '@', 'example.com', '?', 'I', 'need', 'to', 'contact', 'him', 'ASAP', '.', 'See', 'you', 'at', '5:00', 'PM', 'tomorrow', '!']\n"
     ]
    }
   ],
   "source": [
    "Tokens = word_tokenize(text)\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Tokens: \\n{Tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c7568-0752-4b87-a68c-52a50f78ec59",
   "metadata": {},
   "source": [
    "6. ### StopWord\n",
    "   Stopword are the most commonly occurinng words in any language, e.g. Urdu have different, English have different.\n",
    "   For the model to trained, we don't require the repeated words, it's redundant for the model to be trained on. By this way we reduced the size of our data. So the training time will be less as well as for the computional resourses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "6da4096e-f4b7-40f1-9d7a-d91d144d7025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\faizr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "7bb5073a-08d9-4cb4-8705-7dc738ded74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "['Heyi', '!', 'Have', 'yu', 'visited', 'https', ':', '//example.com', 'recently', '?', 'It', \"'s\", 'amazing', '!', 'I', 'bought', '2', 'new', 'gadgets', 'sale', 'last', 'week', '(', 'crazy', 'deals', '!', ')', '.', 'The', 'total', 'cost', '$', '199.99â€”what', 'bargain', '!', 'ðŸ˜Š', 'But', 'I', 'â€™', 'bit', 'concerned', 'data', 'privacy', '...', 'ðŸ¤”', 'Are', 'really', 'protecting', 'information', '?', 'By', 'way', ',', 'know', 'John', 'â€™', 'email', 'john.doe123', '@', 'example.com', '?', 'I', 'need', 'contact', 'ASAP', '.', 'See', '5:00', 'PM', 'tomorrow', '!']\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "noStopWords = [word for word in Tokens if word not in stopWords]\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{noStopWords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53107d-1c46-4e05-93cc-6ab62148bc4b",
   "metadata": {},
   "source": [
    "7. ### Stemming/Lemmatization\n",
    "   Stemming and Lemmatization are two similar but not the same things, in stemming we set a word from the words to obtain the root of the word. e.g. running, runner, ran will be stemmed as run. and for the Lemmatization we get the word that is the parent for other words e.g. running will be Lemmatized as run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "06f4e41d-dff3-4bf4-a6dc-b440bbbdc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "61cdce57-6401-452f-afc2-e30b0784d127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "['heyi', 'there', '!', 'have', 'yu', 'visit', 'http', ':', '//example.com', 'recent', '?', 'it', \"'s\", 'amaz', '!', 'i', 'bought', '2', 'new', 'gadget', 'from', 'their', 'sale', 'last', 'week', '(', 'crazi', 'deal', '!', ')', '.', 'the', 'total', 'cost', 'wa', '$', '199.99â€”what', 'a', 'bargain', '!', 'ðŸ˜Š', 'but', 'i', 'â€™', 'm', 'a', 'bit', 'concern', 'about', 'my', 'data', 'privaci', '...', 'ðŸ¤”', 'are', 'they', 'realli', 'protect', 'my', 'inform', '?', 'by', 'the', 'way', ',', 'do', 'you', 'know', 'if', 'john', 'â€™', 's', 'email', 'is', 'john.doe123', '@', 'example.com', '?', 'i', 'need', 'to', 'contact', 'him', 'asap', '.', 'see', 'you', 'at', '5:00', 'pm', 'tomorrow', '!']\n"
     ]
    }
   ],
   "source": [
    "stem = PorterStemmer()\n",
    "\n",
    "stemWords = [stem.stem(word) for word in Tokens]\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{stemWords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "5d3fbfa9-d267-4900-af1b-96d498861df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\faizr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\faizr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "015d4cac-f33b-4e0d-96f3-fa601055f470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "['Heyi', 'there', '!', 'Have', 'yu', 'visited', 'http', ':', '//example.com', 'recently', '?', 'It', \"'s\", 'amazing', '!', 'I', 'bought', '2', 'new', 'gadget', 'from', 'their', 'sale', 'last', 'week', '(', 'crazy', 'deal', '!', ')', '.', 'The', 'total', 'cost', 'wa', '$', '199.99â€”what', 'a', 'bargain', '!', 'ðŸ˜Š', 'But', 'I', 'â€™', 'm', 'a', 'bit', 'concerned', 'about', 'my', 'data', 'privacy', '...', 'ðŸ¤”', 'Are', 'they', 'really', 'protecting', 'my', 'information', '?', 'By', 'the', 'way', ',', 'do', 'you', 'know', 'if', 'John', 'â€™', 's', 'email', 'is', 'john.doe123', '@', 'example.com', '?', 'I', 'need', 'to', 'contact', 'him', 'ASAP', '.', 'See', 'you', 'at', '5:00', 'PM', 'tomorrow', '!']\n"
     ]
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "lemWords = [lem.lemmatize(word) for word in Tokens]\n",
    "\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{lemWords}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd59e6-e47e-42f2-9bb4-51f3d86ba37b",
   "metadata": {},
   "source": [
    "8. ### Special Characters\n",
    "   Special Characters and Punctuation are common in text preprocessing for NLP.One can may choose to replace or remove, depond upon thescenarioss of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "97a386a2-d3cf-4548-bf85-00eb783d5b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "Heyi there Have yu visited httpsexamplecom recently Its amazing I bought 2 new gadgets from their sale last week crazy deals The total cost was 19999what a bargain  But Im a bit concerned about my data privacy  Are they really protecting my information By the way do you know if Johns email is johndoe123examplecom I need to contact him ASAP See you at 500 PM tomorrow\n"
     ]
    }
   ],
   "source": [
    "clean = re.sub(r'[^\\w\\s]', '', text)\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{clean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0b2ee-e38b-423b-b4de-3301e873236a",
   "metadata": {},
   "source": [
    "9. ### Spelling Correction\n",
    "    Spelling Correction is the most crucial in the text/natural language, we human may able to get the meaning of the slightly miscorrect words, but the machine will output on what the training has be done so it's crucial to correct the spelling in the NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c3e665da-08b7-41f1-b9e2-a6db35b4a000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "59824a07-b4e9-4d1a-92f9-43b992fff496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "['Heyi', 'there', '!', 'Have', 'you', 'visited', 'hates', ':', '', 'recently', '?', 'It', 'is', 'amazing', '!', 'I', 'bought', '2', 'new', 'gadgets', 'from', 'their', 'sale', 'last', 'week', '(', 'crazy', 'deals', '!', ')', '.', 'The', 'total', 'cost', 'was', '$', '', 'a', 'bargain', '!', 'i', 'But', 'I', 'i', 'm', 'a', 'bit', 'concerned', 'about', 'my', 'data', 'privacy', '', 'i', 'Are', 'they', 'really', 'protecting', 'my', 'information', '?', 'By', 'the', 'way', ',', 'do', 'you', 'know', 'if', 'John', 'i', 's', 'email', 'is', '', '@', '', '?', 'I', 'need', 'to', 'contact', 'him', 'ASAP', '.', 'See', 'you', 'at', '', 'PM', 'tomorrow', '!']\n",
      "\n",
      "This is the corrected text: \n",
      "Heyi there ! Have you visited hates :  recently ? It is amazing ! I bought 2 new gadgets from their sale last week ( crazy deals ! ) . The total cost was $  a bargain ! i But I i m a bit concerned about my data privacy  i Are they really protecting my information ? By the way , do you know if John i s email is  @  ? I need to contact him ASAP . See you at  PM tomorrow !\n"
     ]
    }
   ],
   "source": [
    "spell = SpellChecker()\n",
    "notCorrect = spell.unknown(Tokens)\n",
    "correctWords = [spell.correction(word) if word in notCorrect else word for word in Tokens]\n",
    "correctWords = [word if word is not None else \"\" for word in correctWords]\n",
    "correctText = ' '.join(correctWords)\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{correctWords}\\n\\nThis is the corrected text: \\n{correctText}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7f016-ce7d-4457-9458-438e83f14b43",
   "metadata": {},
   "source": [
    "10. ### POS\n",
    "    POS is part-of-speech tagging, it's crucial in natural language, cause it's grammer, if your model is inferencing with wrong grammer, it make no sense to use this kind of model in the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "547a9c07-122a-4b81-bd2d-aaf5b5bdfd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "3f1c055c-1ed6-458e-9219-17dbcc50b35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "[('Heyi', 'NNP'), ('there', 'EX'), ('!', '.'), ('Have', 'VBP'), ('yu', 'VBN'), ('visited', 'VBN'), ('https', 'NN'), (':', ':'), ('//example.com', 'NN'), ('recently', 'RB'), ('?', '.'), ('It', 'PRP'), (\"'s\", 'VBZ'), ('amazing', 'JJ'), ('!', '.'), ('I', 'PRP'), ('bought', 'VBD'), ('2', 'CD'), ('new', 'JJ'), ('gadgets', 'NNS'), ('from', 'IN'), ('their', 'PRP$'), ('sale', 'NN'), ('last', 'JJ'), ('week', 'NN'), ('(', '('), ('crazy', 'JJ'), ('deals', 'NNS'), ('!', '.'), (')', ')'), ('.', '.'), ('The', 'DT'), ('total', 'JJ'), ('cost', 'NN'), ('was', 'VBD'), ('$', '$'), ('199.99â€”what', 'CD'), ('a', 'DT'), ('bargain', 'NN'), ('!', '.'), ('ðŸ˜Š', 'NN'), ('But', 'CC'), ('I', 'PRP'), ('â€™', 'VBP'), ('m', 'RB'), ('a', 'DT'), ('bit', 'NN'), ('concerned', 'JJ'), ('about', 'IN'), ('my', 'PRP$'), ('data', 'NNS'), ('privacy', 'NN'), ('...', ':'), ('ðŸ¤”', 'CC'), ('Are', 'VBP'), ('they', 'PRP'), ('really', 'RB'), ('protecting', 'VBG'), ('my', 'PRP$'), ('information', 'NN'), ('?', '.'), ('By', 'IN'), ('the', 'DT'), ('way', 'NN'), (',', ','), ('do', 'VBP'), ('you', 'PRP'), ('know', 'VB'), ('if', 'IN'), ('John', 'NNP'), ('â€™', 'NNP'), ('s', 'NN'), ('email', 'NN'), ('is', 'VBZ'), ('john.doe123', 'JJ'), ('@', 'NNP'), ('example.com', 'NN'), ('?', '.'), ('I', 'PRP'), ('need', 'VBP'), ('to', 'TO'), ('contact', 'VB'), ('him', 'PRP'), ('ASAP', 'NNP'), ('.', '.'), ('See', 'VB'), ('you', 'PRP'), ('at', 'IN'), ('5:00', 'CD'), ('PM', 'NNP'), ('tomorrow', 'NN'), ('!', '.')]\n"
     ]
    }
   ],
   "source": [
    "pos = pos_tag(Tokens)\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be2ae59-dcbf-4121-bfa4-5ac4ad95c8ff",
   "metadata": {},
   "source": [
    "11. ### Contractions\n",
    "    Handling contractions is an important step in text preprocessing. Contractions are shortened forms of words or phrases, often formed by combining two words, and they are commonly used in everyday language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "909d7801-0ac2-4f51-9480-674e8eaa553b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the Original Text: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But Iâ€™m a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n",
      "\n",
      "This one is the Modified: \n",
      "Heyi there! Have yu visited https://example.com recently? It's amazing! I bought 2 new gadgets from their sale last week (crazy deals!). The total cost was $199.99â€”what a bargain! ðŸ˜Š But I am a bit concerned about my data privacy... ðŸ¤” Are they really protecting my information? By the way, do you know if Johnâ€™s email is john.doe123@example.com? I need to contact him ASAP. See you at 5:00 PM tomorrow!\n"
     ]
    }
   ],
   "source": [
    "contractions_dict = {\n",
    "    \"isn't\": \"is not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"Iâ€™m\": \"I am\",  # Adding the contraction with the curly apostrophe\n",
    "    \"it's\": \"it is\",\n",
    "    \"Itâ€™s\": \"it is\"  # Adding the contraction with the curly apostrophe\n",
    "}\n",
    "\n",
    "modified_text = text\n",
    "for contraction, expansion in contractions_dict.items():\n",
    "    modified_text = modified_text.replace(contraction, expansion)\n",
    "\n",
    "print(f\"This is the Original Text: \\n{text}\\n\\nThis one is the Modified: \\n{modified_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
